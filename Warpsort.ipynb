{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Warpsort.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["F9PmBZql0ow4","8h2dznwofM8M","iUYP4kCJhEIx"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vjwQzqG-epop"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# CUDA setup"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5YlC1IOTlNb"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8h2dznwofM8M"},"source":["# CD"]},{"cell_type":"code","metadata":{"id":"qDzEZEUOfI_w"},"source":["%cd /content/drive/MyDrive/GPU_Computing_Project\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["#DeviceQuery"]},{"cell_type":"code","metadata":{"id":"qDVlDmZbirAW"},"source":["#@title working directory: **deviceQuery/**\n","%cd /content/drive/MyDrive/GPU_Computing_Project/deviceQuery\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPaV4DfPh26Q"},"source":["%%writefile ./helper.h\n","// Beginning of GPU Architecture definitions\n","inline int _ConvertSMVer2Cores(int major, int minor) {\n","\t// Defines for GPU Architecture types (using the SM version to determine\n","\t// the # of cores per SM\n","\ttypedef struct {\n","\t\tint SM;  // 0xMm (hexidecimal notation), M = SM Major version,\n","\t\t// and m = SM minor version\n","\t\tint Cores;\n","\t} sSMtoCores;\n","\n","\tsSMtoCores nGpuArchCoresPerSM[] = {\n","\t\t\t{0x20, 32},\n","\t\t\t{0x30, 192},\n","\t\t\t{0x32, 192},\n","\t\t\t{0x35, 192},\n","\t\t\t{0x37, 192},\n","\t\t\t{0x50, 128},\n","\t\t\t{0x52, 128},\n","\t\t\t{0x53, 128},\n","\t\t\t{0x60,  64},\n","\t\t\t{0x61, 128},\n","\t\t\t{0x62, 128},\n","\t\t\t{0x70,  64},\n","\t\t\t{0x72,  64},\n","\t\t\t{0x75,  64},\n","\t\t\t{-1, -1}};\n","\n","\tint index = 0;\n","\n","\twhile (nGpuArchCoresPerSM[index].SM != -1) {\n","\t\tif (nGpuArchCoresPerSM[index].SM == ((major << 4) + minor)) {\n","\t\t\treturn nGpuArchCoresPerSM[index].Cores;\n","\t\t}\n","\n","\t\tindex++;\n","\t}\n","\n","\t// If we don't find the values, we default use the previous one\n","\t// to run properly\n","\tprintf(\n","\t\t\t\"MapSMtoCores for SM %d.%d is undefined.\"\n","\t\t\t\"  Default to use %d Cores/SM\\n\",\n","\t\t\tmajor, minor, nGpuArchCoresPerSM[index - 1].Cores);\n","\treturn nGpuArchCoresPerSM[index - 1].Cores;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vvl8WXljg0WK"},"source":["%%writefile ./deviceQuery.cu\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"helper.h\"\n","#include \"../utils/common.h\"\n","\n","int main(void) {\n","\n","\tprintf(\"\\nCUDA Device Query (Runtime API) version (CUDART static linking)\\n\\n\");\n","\tint deviceCount = 0;\n","\tCHECK(cudaGetDeviceCount(&deviceCount));\n","\n","\t// This function call returns 0 if there are no CUDA capable devices.\n","\tif (deviceCount == 0)\n","\t\tprintf(\"There are no available device(s) that support CUDA\\n\");\n","\telse\n","\t\tprintf(\"Detected %d CUDA Capable device(s)\\n\", deviceCount);\n","\n","\tint dev, driverVersion = 0, runtimeVersion = 0;\n","\n","\tfor (dev = 0; dev < deviceCount; ++dev) {\n","\t\tcudaSetDevice(dev);\n","\t\tcudaDeviceProp deviceProp;\n","\t\tcudaGetDeviceProperties(&deviceProp, dev);\n","\n","\t\tprintf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","\n","\t\tcudaDriverGetVersion(&driverVersion);\n","\t\tcudaRuntimeGetVersion(&runtimeVersion);\n","\n","\t\tprintf(\"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n\",\n","\t\t\t\tdriverVersion / 1000, (driverVersion % 100) / 10,\n","\t\t\t\truntimeVersion / 1000, (runtimeVersion % 100) / 10);\n","\n","\t\tprintf(\"  CUDA Capability Major/Minor version number:    %d.%d\\n\",\n","\t\t\t\tdeviceProp.major, deviceProp.minor);\n","\n","\t\tprintf(\"  Total amount of global memory:                 %.0f MBytes (%llu bytes)\\n\",\n","\t\t\t\t(float) deviceProp.totalGlobalMem / 1048576.0f,\n","\t\t\t\t(unsigned long long) deviceProp.totalGlobalMem);\n","\n","\t    printf(\"  (%2d) Multiprocessors, (%3d) CUDA Cores/MP:     %d CUDA Cores\\n\",\n","\t           deviceProp.multiProcessorCount,\n","\t           _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),\n","\t           _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) *\n","\t               deviceProp.multiProcessorCount);\n","\n","\t\tprintf(\"  GPU Max Clock rate:                            %.0f MHz (%0.2f GHz)\\n\",\n","\t\t\t\tdeviceProp.clockRate * 1e-3f, deviceProp.clockRate * 1e-6f);\n","\n","\t\tprintf(\"  Memory Clock rate:                             %.0f Mhz\\n\", deviceProp.memoryClockRate * 1e-3f);\n","\t\tprintf(\"  Memory Bus Width:                              %d-bit\\n\", deviceProp.memoryBusWidth);\n","\t\tif (deviceProp.l2CacheSize)\n","\t\t\tprintf(\"  L2 Cache Size:                                 %d bytes\\n\", deviceProp.l2CacheSize);\n","\n","\t\tprintf(\"  Maximum Texture Dimension Size (x,y,z)         1D=(%d), 2D=(%d, %d), 3D=(%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxTexture1D, deviceProp.maxTexture2D[0],\n","\t\t\t\tdeviceProp.maxTexture2D[1], deviceProp.maxTexture3D[0],\n","\t\t\t\tdeviceProp.maxTexture3D[1], deviceProp.maxTexture3D[2]);\n","\n","\t\tprintf(\"  Maximum Layered 1D Texture Size, (num) layers  1D=(%d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture1DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture1DLayered[1]);\n","\n","\t\tprintf(\"  Maximum Layered 2D Texture Size, (num) layers  2D=(%d, %d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture2DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[1],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[2]);\n","\n","\t\tprintf(\"  Total amount of constant memory:               %lu bytes\\n\",\n","\t\t\t\tdeviceProp.totalConstMem);\n","\t\tprintf(\"  Total amount of shared memory per block:       %lu bytes\\n\",\n","\t\t\t\tdeviceProp.sharedMemPerBlock);\n","\t\tprintf(\"  Total number of registers available per block: %d\\n\",\n","\t\t\t\tdeviceProp.regsPerBlock);\n","\t\tprintf(\"  Warp size:                                     %d\\n\",\n","\t\t\t\tdeviceProp.warpSize);\n","\t\tprintf(\"  Maximum number of threads per multiprocessor:  %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerMultiProcessor);\n","\t\tprintf(\"  Maximum number of threads per block:           %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerBlock);\n","\t\tprintf(\"  Max dimension size of a thread block (x,y,z): (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1],\n","\t\t\t\tdeviceProp.maxThreadsDim[2]);\n","\t\tprintf(\"  Max dimension size of a grid size    (x,y,z): (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxGridSize[0], deviceProp.maxGridSize[1],\n","\t\t\t\tdeviceProp.maxGridSize[2]);\n","\t\tprintf(\"  Maximum memory pitch:                          %lu bytes\\n\",\n","\t\t\t\tdeviceProp.memPitch);\n","\t\tprintf(\"  Texture alignment:                             %lu bytes\\n\",\n","\t\t\t\tdeviceProp.textureAlignment);\n","\t\tprintf(\"  Concurrent copy and kernel execution:          %s with %d copy engine(s)\\n\",\n","\t\t\t\t(deviceProp.deviceOverlap ? \"Yes\" : \"No\"),\n","\t\t\t\tdeviceProp.asyncEngineCount);\n","\t\tprintf(\"  Run time limit on kernels:                     %s\\n\",\n","\t\t\t\tdeviceProp.kernelExecTimeoutEnabled ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Integrated GPU sharing Host Memory:            %s\\n\",\n","\t\t\t\tdeviceProp.integrated ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Support host page-locked memory mapping:       %s\\n\",\n","\t\t\t\tdeviceProp.canMapHostMemory ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Alignment requirement for Surfaces:            %s\\n\",\n","\t\t\t\tdeviceProp.surfaceAlignment ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device has ECC support:                        %s\\n\",\n","\t\t\t\tdeviceProp.ECCEnabled ? \"Enabled\" : \"Disabled\");\n","\n","\t\tprintf(\"  Device supports Unified Addressing (UVA):      %s\\n\",\n","\t\t\t\tdeviceProp.unifiedAddressing ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device PCI Domain ID / Bus ID / location ID:   %d / %d / %d\\n\",\n","\t\t\t\tdeviceProp.pciDomainID, deviceProp.pciBusID,\n","\t\t\t\tdeviceProp.pciDeviceID);\n","\t}\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc deviceQuery.cu -o deviceQuery\n","!./deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eA96rdPIi8lO"},"source":["# WarpSort"]},{"cell_type":"markdown","metadata":{"id":"Y_KtdBSNjJeU"},"source":["Qua ci va l'introduzione\n","\n","\n","*   In cosa consiste l'algoritmo \n","*   Come viene implementato\n","*   Caso sequenziale\n","*   Caso parallelo\n","*   Test e risultati\n","*   Conclusioni\n","\n"]},{"cell_type":"code","metadata":{"id":"h4pIymTnjH1T"},"source":["%cd /content/drive/MyDrive/GPU_Computing_Project/WarpSort/\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqtxHaG-kHfR"},"source":["%%writefile ./WarpSort.cu\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <time.h>\n","#include <math.h>\n","\n","#include \"../utils/common.h\"\n","\n","#define THREADS 128\n","#define BLOCKS 8\n","\n","/*Divide the input sequence into equal-sized subsequences. \n","  Each subsequence will be sorted by an independent warp using the bitonic network.*/\n","__global__ void bitonic_sort_warp(int *keyin){\n","  //prendere thread id giusto tenendo in considerazione k_0 e k_1\n","  //implementare gli swap fatti bene dentro la funzione\n","  unsigned int id = threadIdx.x + blockDim.x * blockIdx.x;\n","  unsigned int subseq = id / 32; //in quale sottosequenza dell'array siamo\n","  unsigned int start = 128 * subseq; //primo elemento della sottosequenza da riordinare\n","\n","  int i = 0,j = 0;\n","  int phase = 0, stage = 0;\n","  int k_0 = 0, k_1 = 0;\n","  int u = 0, index1 = 0, index2 = 0, p = 0, q = 0, m = 0, o = 0, um = 0, pm = 0;\n","  float dim = 0;\n","\n","  //phase 0 to log(128)-1 \n","  for(i=2; i<128 ;i*=2){ \n","    stage = 0;\n","\n","\n","    dim = i*2;\n","    u = ceil( (threadIdx.x+1) * (4/dim) ); //indice della sottosequenza simmetrica a cui il thread appartiene\n","    //printf(\"thread %d : u = %d \\n\", threadIdx.x, u);\n","\n","    index1 = (u - 1) * dim;\n","    index2 = index1 + dim - 1;\n","\n","    for(j = i/2; j > 0; j /= 2){ \n","      /*\n","      if (threadIdx.x == 0)\n","        printf(\"thread %d : phase = %d, stage = %d \\n\", threadIdx.x, phase, stage);\n","      */\n","      p = threadIdx.x - (u - 1) * (dim / 4); // posizione del thread nella sottosequenza simmetrica\n","      //printf(\"thread %d : p = %d \\n\", threadIdx.x, p);\n","\n","      //q è l'offset usato poi per k_0 e k_1\n","      if (stage == 0) { // primo stage della fase\n","          q = p;\n","      }\n","      if (stage != 0 && stage != phase){ //né primo né ultimo stage della fase\n","          \n","          //int n = 2 ^ stage; // numero di minisequenze\n","          m = j; // numero di freccie rosse per minisequenza\n","          o = j * 2; //offset speciale tra minisequenza e l'altra\n","\n","          um = (int)(p / m); //indice della minisequenza a cui il thread appartiene\n","\n","          pm = p - um * m; //posizione del thread nella minisequenza\n","          q = pm + o * um;\n","      }\n","      if (stage == phase){ //ultimo stage della fase\n","          q = p * 2;\n","      }\n","      k_0 = index1 + q;\n","      k_1 = index2 - q; \n","\n","      k_0 = start + k_0;\n","      k_1 = start + k_1; \n","      \n","      //printf(\"thread %d : k_0 = %d, k_1 = %d \\n\", threadIdx.x, k_0, k_1);\n","\n","      //k_0 ? position of preceding element in each pair to form ascending order\n","      if(keyin[k_0] > keyin[k_0+j]) {\n","        int tmp = keyin[k_0];\n","        keyin[k_0] = keyin[k_0+j];\n","        keyin[k_0+j] = tmp;\n","      }\n","      //k1 ? position of preceding element in each pair to form descending order\n","      if(keyin[k_1] > keyin[k_1-j]){\n","        int tmp = keyin[k_1];\n","        keyin[k_1] = keyin[k_1-j];\n","        keyin[k_1-j] = tmp;\n","      }\n","\n","      stage++;\n","    }\n","    phase++;\n","  }\n","\n","  stage = 0;\n","  //special case for the last phase \n","  for(j=128/2; j>0; j/=2){\n","    \n","    dim = j * 2;\n","    if (dim < 4) dim = 4;\n","    u = ceil( (threadIdx.x+1) * (4/dim) ); //indice della sottosequenza simmetrica a cui il thread appartiene\n","\n","    //printf(\"thread %d : u = %d \\n\", threadIdx.x, u);\n","\n","    index1 = (u - 1) * dim;\n","    index2 = index1 + dim - 1;\n","\n","    p = threadIdx.x - (u - 1) * (dim / 4); // posizione del thread nella sottosequenza simmetrica\n","\n","    //q è l'offset usato poi per k_0 e k_1\n","    \n","    q = p;\n","        \n","    k_0 = index1 + q;\n","    k_1 = index2 - q; \n","\n","    k_0 = start + k_0;\n","    k_1 = start + k_1;\n","\n","    /*\n","    if (threadIdx.x == 0)\n","        printf(\"thread %d : stage = %d, offset = %d \\n\", threadIdx.x, stage, j);\n","    printf(\"thread %d : k_0 = %d, k_1 = %d \\n\", threadIdx.x, k_0, k_1);\n","    */\n","      \n","    //k0 ? position of preceding element in the thread's first pair to form ascending order\n","    if(keyin[k_0] > keyin[k_0+j]){\n","        int tmp = keyin[k_0];\n","        keyin[k_0] = keyin[k_0 + j];\n","        keyin[k_0 + j] = tmp;\n","    }\n","\n","    //k1 ? position of preceding element in the thread's second pair to form ascending order\n","    if(keyin[k_1] < keyin[k_1 - j]){\n","        int tmp = keyin[k_1];\n","        keyin[k_1] = keyin[k_1 - j];\n","        keyin[k_1 - j] = tmp;\n","    }\n","\n","    stage++;\n","  }\n","  \n","}\n","\n","/*The parameter dir indicates the sorting direction, ASCENDING\n"," or DESCENDING; if (a[i] > a[j]) agrees with the direction,\n"," then a[i] and a[j] are interchanged.*/\n","void compAndSwap(int a[], int i, int j, int dir) {\n","\tif (dir == (a[i] > a[j])) {\n","\t\tint tmp = a[i];\n","\t\ta[i] = a[j];\n","\t\ta[j] = tmp;\n","\t}\n","}\n","\n","/*It recursively sorts a bitonic sequence in ascending order,\n"," if dir = 1, and in descending order otherwise (means dir=0).\n"," The sequence to be sorted starts at index position low,\n"," the parameter cnt is the number of elements to be sorted.*/\n","void bitonicMerge(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\t\tfor (int i = low; i < low + k; i++)\n","\t\t\tcompAndSwap(a, i, i + k, dir);\n","\t\tbitonicMerge(a, low, k, dir);\n","\t\tbitonicMerge(a, low + k, k, dir);\n","\t}\n","}\n","\n","/* This function first produces a bitonic sequence by recursively\n"," sorting its two halves in opposite sorting orders, and then\n"," calls bitonicMerge to make them in the same order */\n","void bitonicSort(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\n","\t\t// sort in ascending order since dir here is 1\n","\t\tbitonicSort(a, low, k, 1);\n","\n","\t\t// sort in descending order since dir here is 0\n","\t\tbitonicSort(a, low + k, k, 0);\n","\n","\t\t// Will merge wole sequence in ascending order\n","\t\t// since dir=1.\n","\t\tbitonicMerge(a, low, cnt, dir);\n","\t}\n","}\n","\n","/*\n"," * test bitonic sort on CPU and GPU\n"," */\n","int main(void) {\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\tint N = THREADS*BLOCKS;\n","\t// check\n","\tif (!(N && !(N & (N - 1)))) {\n","\t\tprintf(\"ERROR: N must be power of 2 (N = %d)\\n\", N);\n","\t\texit(1);\n","\t}\n","\tsize_t nBytes = N * sizeof(int);\n","\tint *a = (int*) malloc(nBytes);\n","\tint *b = (int*) malloc(nBytes);\n","\n","\t// fill data\n","\tfor (int i = 0; i < N; ++i) {\n","\t\t//a[i] =  i%5; //rand() % 100; // / (float) RAND_MAX;\n","    a[i] = rand() % 100;\n","\t\tb[i] = a[i];\n","\t}\n","\n","\t// bitonic CPU\n","\tdouble cpu_time = seconds();\n","\n","  bitonicSort(b, 0, N, 1);   // 1 means sort in ascending order\n","\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", seconds()-cpu_time);\n","\n","\t// device mem copy\n","\tint *d_a;\n","\tCHECK(cudaMalloc((void**) &d_a, nBytes));\n","\tCHECK(cudaMemcpy(d_a, a, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// num of threads\n","\tdim3 blocks(BLOCKS, 1);   // Number of blocks\n","\t//dim3 threads(THREADS, 1); // Number of threads\n","  dim3 threads(THREADS / 4, 1); // Number of threads\n","\t\n","  /*\n","\tint j, k;\n","  // external loop on comparators of size k\n","  for (k = 2; k <= N; k <<= 1) {\n","    // internal loop for comparator internal stages\n","    for (j = k >> 1; j > 0; j = j >> 1)\n","      bitonic_sort_step<<<blocks, threads>>>(d_a, j, k);\n","  }\n","  */\n","\t\n","  // start computation\n","\tcudaEventRecord(start);\n","  /*Divide the input sequence into equal-sized subsequences. \n","  Each subsequence will be sorted by an independent warp using the bitonic network.*/\n","  bitonic_sort_warp<<<blocks, threads>>>(d_a);\n","\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"GPU elapsed time: %.5f (sec)\\n\", milliseconds / 1000);\n","\n","\t// recover data\n","\tcudaMemcpy(a, d_a, nBytes, cudaMemcpyDeviceToHost);\n","\n","\t// print & check\n","\tif (N < 500) {\n","\t\tprintf(\"GPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i){\n","      if(i % 128 == 0)\n","        printf(\"sottosequenza, indice = %d\\n\", i);\n","      printf(\"%d\\n\", a[i]);\n","    }\n","\t\t\t\n","      /*\n","\t\tprintf(\"CPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i)\n","\t\t\tprintf(\"%d\\n\", b[i]);\n","      */\n","\t}\n","\telse {\n","    /*\n","\t\tfor (int i = 0; i < N; ++i) {\n","\t\t\tif (a[i] != b[i]) {\n","\t\t\t\tprintf(\"ERROR a[%d] != b[%d]  (a[i] = %d  -  b[i] = %d\\n\", i,i, a[i],b[i]);\n","\t\t\t\tbreak;\n","\t\t\t}\n","\t\t}*/\n","\t}\n","\n","\tcudaFree(d_a);\n","\texit(0);\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-wjq_suoB0z"},"source":["# compilatore\n","\n","!nvcc -arch=sm_37 WarpSort.cu -o WarpSort \n","! ./WarpSort\n"],"execution_count":null,"outputs":[]}]}